{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a4d814a-ce48-461c-a40a-9ebbe7a9362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting API Keys\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your api key\"\n",
    "os.environ[\"SERPAPI_KEY\"] = \"your api key\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b80f644-d0b8-4bf0-9b9f-32d06480318b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your research query:  Latest Trends in AI\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "\n",
      "=======================\n",
      "SUMMARY\n",
      "=======================\n",
      "## Executive Summary on Latest Trends in AI (2025 AI Index Report)\n",
      "\n",
      "### 1. Key Insights\n",
      "- **Efficiency and Accessibility**: AI technologies are becoming increasingly efficient and affordable, making them more accessible to a broader audience.\n",
      "- **Open vs. Closed Models**: Open-weight models are gaining traction, closing the performance gap with closed models, which enhances diversity in AI solutions.\n",
      "\n",
      "### 2. Trends\n",
      "- **AI Benchmark Saturation**: Indicators suggest that existing benchmarks for AI performance are reaching saturation, prompting a need for diversification in evaluation methods.\n",
      "- **Transcending Transformers**: The evolution beyond traditional transformer architectures is anticipated, suggesting new methodologies and advancements in AI models.\n",
      "- **Embodied AI and World Models**: There's a growing emphasis on embodied AI, which involves AI that interacts with and understands the physical world.\n",
      "- **Privacy vs. Personalization**: A debate is emerging over balancing user privacy with the demand for personalized AI experiences.\n",
      "- **Emotional AI**: The development of AI systems that can understand and react to human emotions is becoming a focal point.\n",
      "- **Resource Efficiency**: Innovations are addressing the resource demands of AI, particularly in improving energy efficiency without compromising performance.\n",
      "\n",
      "### 3. Recommended Next Steps\n",
      "- **Adapt Strategies**: Organizations should adapt their AI strategies to focus on open-weight models and invest in research exploring new architectures beyond transformers.\n",
      "- **Evaluate Privacy Concerns**: Companies must prioritize user privacy while exploring personalized AI solutions, ensuring they comply with regulations.\n",
      "- **Monitor Emotion Recognition Technologies**: Stay informed about developments in emotional AI to better harness its potential for creating empathetic and responsive applications.\n",
      "- **Invest in Resource Efficiency**: Explore partnerships and technologies aimed at improving the energy efficiency of AI systems to prepare for a resource-constrained future.\n",
      "\n",
      "This summary encapsulates the latest insights and trends in AI as highlighted in various reports and research, providing a roadmap for organizations to remain competitive in an evolving landscape.\n",
      "\n",
      "=======================\n",
      "RECENT MEMORY\n",
      "=======================\n",
      "(26, 'summary', \"## Executive Summary on Latest Trends in AI (2025 AI Index Report)\\n\\n### 1. Key Insights\\n- **Efficiency and Accessibility**: AI technologies are becoming increasingly efficient and affordable, making them more accessible to a broader audience.\\n- **Open vs. Closed Models**: Open-weight models are gaining traction, closing the performance gap with closed models, which enhances diversity in AI solutions.\\n\\n### 2. Trends\\n- **AI Benchmark Saturation**: Indicators suggest that existing benchmarks for AI performance are reaching saturation, prompting a need for diversification in evaluation methods.\\n- **Transcending Transformers**: The evolution beyond traditional transformer architectures is anticipated, suggesting new methodologies and advancements in AI models.\\n- **Embodied AI and World Models**: There's a growing emphasis on embodied AI, which involves AI that interacts with and understands the physical world.\\n- **Privacy vs. Personalization**: A debate is emerging over balancing user privacy with the demand for personalized AI experiences.\\n- **Emotional AI**: The development of AI systems that can understand and react to human emotions is becoming a focal point.\\n- **Resource Efficiency**: Innovations are addressing the resource demands of AI, particularly in improving energy efficiency without compromising performance.\\n\\n### 3. Recommended Next Steps\\n- **Adapt Strategies**: Organizations should adapt their AI strategies to focus on open-weight models and invest in research exploring new architectures beyond transformers.\\n- **Evaluate Privacy Concerns**: Companies must prioritize user privacy while exploring personalized AI solutions, ensuring they comply with regulations.\\n- **Monitor Emotion Recognition Technologies**: Stay informed about developments in emotional AI to better harness its potential for creating empathetic and responsive applications.\\n- **Invest in Resource Efficiency**: Explore partnerships and technologies aimed at improving the energy efficiency of AI systems to prepare for a resource-constrained future.\\n\\nThis summary encapsulates the latest insights and trends in AI as highlighted in various reports and research, providing a roadmap for organizations to remain competitive in an evolving landscape.\", '2025-11-23 13:59:09')\n",
      "(25, 'research_raw', \"6 AI trends you'll see more of in 2025\\nUnable to fetch content: HTTPSConnectionPool(host='news.microsoft.com', port=443): Max retries exceeded with url: /source/features/ai/6-ai-trends-youll-see-more-of-in-2025/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)')))\", '2025-11-23 13:59:00')\n",
      "(24, 'research_raw', \"McKinsey technology trends outlook 2025\\nUnable to fetch content: HTTPSConnectionPool(host='www.mckinsey.com', port=443): Max retries exceeded with url: /capabilities/tech-and-ai/our-insights/the-top-trends-in-tech (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)')))\", '2025-11-23 13:58:59')\n",
      "(23, 'research_raw', \"AI News | Latest AI News, Analysis & Events\\nUnable to fetch content: HTTPSConnectionPool(host='www.artificialintelligence-news.com', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)')))\", '2025-11-23 13:58:59')\n",
      "(22, 'research_raw', \"The Top Artificial Intelligence Trends\\nUnable to fetch content: HTTPSConnectionPool(host='www.ibm.com', port=443): Max retries exceeded with url: /think/insights/artificial-intelligence-trends (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)')))\", '2025-11-23 13:58:58')\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import os\n",
    "import requests, sqlite3, time, re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List, Dict, Tuple\n",
    "from openai import OpenAI\n",
    "\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# Read keys from environment\n",
    "SERPAPI_KEY = os.getenv(\"SERPAPI_KEY\", \"\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "\n",
    "if not SERPAPI_KEY or not OPENAI_API_KEY:\n",
    "    raise RuntimeError(\"Set SERPAPI_KEY and OPENAI_API_KEY as environment variables instead of hardcoding them.\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# ================================\n",
    "# GUARDRAILS\n",
    "# ================================\n",
    "# store lower-case, canonical words\n",
    "PROFANITY = {\n",
    "    \"kill\",\"hack\",\"murder\",\"harass\",\n",
    "    \"assault\",\"attack\",\"abuse\",\"threaten\",\"stalk\",\n",
    "    \"shoot\",\"stab\",\"kidnap\",\"torture\",\"poison\",\n",
    "    \"destroy\",\"bomb\",\"explode\",\"harm\",\"injure\",\"sabotage\",\"strangle\",\"burn\"\n",
    "}\n",
    "\n",
    "# compile a regex pattern for word-boundary, case-insensitive checks\n",
    "_PROFANITY_PATTERN = re.compile(r\"\\b(\" + \"|\".join(re.escape(w) for w in PROFANITY) + r\")\\b\", flags=re.IGNORECASE)\n",
    "\n",
    "def sanitize_input(text: str) -> str:\n",
    "    \"\"\"Trim, limit length and remove control characters.\"\"\"\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    text = text.strip()\n",
    "    # remove control characters\n",
    "    text = re.sub(r'[\\x00-\\x1f\\x7f-\\x9f]', ' ', text)\n",
    "    return text\n",
    "\n",
    "def simple_moderation(text: str) -> Tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    Return (ok, message). Uses a regex to detect profanity/banned words with word boundaries.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return True, \"OK\"\n",
    "    text = text.lower()\n",
    "    m = _PROFANITY_PATTERN.search(text)\n",
    "    if m:\n",
    "        matched = m.group(1)\n",
    "        return False, f\"Contains banned word: {matched}\"\n",
    "    return True, \"OK\"\n",
    "\n",
    "# ================================\n",
    "# MEMORY (SQLite)\n",
    "# ================================\n",
    "DB = \"research_memory.db\"\n",
    "\n",
    "def init_db():\n",
    "    conn = sqlite3.connect(DB)\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS memory (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        role TEXT,\n",
    "        content TEXT,\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    );\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def store(role, content):\n",
    "    conn = sqlite3.connect(DB)\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"INSERT INTO memory (role, content) VALUES (?,?)\", (role, content))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def fetch_recent(n=10):\n",
    "    conn = sqlite3.connect(DB)\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"SELECT id, role, content, created_at FROM memory ORDER BY id DESC LIMIT ?\", (n,))\n",
    "    rows = c.fetchall()\n",
    "    conn.close()\n",
    "    return rows\n",
    "\n",
    "# ================================\n",
    "# RETRIEVER (Embeddings + Cosine)\n",
    "# ================================\n",
    "class SimpleRetriever:\n",
    "    def __init__(self):\n",
    "        self.model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "        self.docs = []\n",
    "        self.vecs = None\n",
    "\n",
    "    def add(self, docs: List[Tuple[str, str]]):\n",
    "        # docs = [(id, text)]\n",
    "        texts = [t for _, t in docs]\n",
    "        embeddings = self.model.encode(texts, convert_to_numpy=True)\n",
    "        if self.vecs is None:\n",
    "            self.vecs = embeddings\n",
    "            self.docs = docs.copy()\n",
    "        else:\n",
    "            self.vecs = np.vstack([self.vecs, embeddings])\n",
    "            self.docs.extend(docs)\n",
    "\n",
    "    def retrieve(self, query: str, k: int = 3):\n",
    "        if self.vecs is None or len(self.docs) == 0:\n",
    "            return []  # nothing indexed yet\n",
    "        qv = self.model.encode([query], convert_to_numpy=True)\n",
    "        sims = cosine_similarity(qv, self.vecs)[0]\n",
    "        idx = np.argsort(-sims)[:k]\n",
    "        return [(self.docs[i][0], self.docs[i][1], float(sims[i])) for i in idx]\n",
    "\n",
    "# ================================\n",
    "# SERPAPI SEARCH TOOL\n",
    "# ================================\n",
    "def serpapi_search(query):\n",
    "    url = \"https://serpapi.com/search\"\n",
    "    params = {\n",
    "        \"engine\": \"google\",\n",
    "        \"q\": query,\n",
    "        \"api_key\": SERPAPI_KEY\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(url, params=params, timeout=8, verify = False)  # timeout and default SSL verify\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "    except Exception as e:\n",
    "        # log and return empty\n",
    "        print(\"SerpAPI search error:\", str(e))\n",
    "        return []\n",
    "\n",
    "    if \"organic_results\" not in data:\n",
    "        return []\n",
    "\n",
    "    results = []\n",
    "    for item in data.get(\"organic_results\", [])[:5]:\n",
    "        results.append({\n",
    "            \"title\": item.get(\"title\", \"\"),\n",
    "            \"url\": item.get(\"link\", \"\"),\n",
    "            \"snippet\": item.get(\"snippet\", \"\")\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# ================================\n",
    "# URL FETCH TOOL\n",
    "# ================================\n",
    "def fetch_url_text(url):\n",
    "    try:\n",
    "        r = requests.get(url, timeout=6)\n",
    "        r.raise_for_status()\n",
    "        text = r.text\n",
    "        return text[:3000]  # limit to avoid too long responses\n",
    "    except Exception as e:\n",
    "        return f\"Unable to fetch content: {e}\"\n",
    "\n",
    "# ================================\n",
    "# OPENAI SUMMARY TOOL\n",
    "# ================================\n",
    "def openai_summarize(prompt):\n",
    "    # ensure prompt is sanitized / limited in size\n",
    "    prompt = sanitize_input(prompt)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert summarizer.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    # safe extraction\n",
    "    try:\n",
    "        return response.choices[0].message.content\n",
    "    except Exception:\n",
    "        return \"No summary returned (OpenAI response structure unexpected).\"\n",
    "\n",
    "# ================================\n",
    "# AGENT: ResearchAgent\n",
    "# ================================\n",
    "class ResearchAgent:\n",
    "    def __init__(self, retriever):\n",
    "        self.retriever = retriever\n",
    "\n",
    "    def research(self, query):\n",
    "        # sanitize before moderation and external calls\n",
    "        query = sanitize_input(query)\n",
    "        ok, msg = simple_moderation(query)\n",
    "        if not ok:\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        search_results = serpapi_search(query)\n",
    "        findings = []\n",
    "\n",
    "        for r in search_results:\n",
    "            page_text = fetch_url_text(r[\"url\"])\n",
    "            store(\"research_raw\", r[\"title\"] + \"\\n\" + page_text[:2000])\n",
    "            findings.append({\n",
    "                \"title\": r[\"title\"],\n",
    "                \"url\": r[\"url\"],\n",
    "                \"snippet\": r[\"snippet\"],\n",
    "                \"text\": page_text\n",
    "            })\n",
    "\n",
    "        # Load to retriever\n",
    "        docs = [(f\"doc{i}\", f[\"text\"]) for i, f in enumerate(findings)]\n",
    "        if docs:\n",
    "            self.retriever.add(docs)\n",
    "\n",
    "        return findings\n",
    "\n",
    "# ================================\n",
    "# AGENT: SummaryAgent\n",
    "# ================================\n",
    "class SummaryAgent:\n",
    "    def summarize(self, findings, question):\n",
    "        prompt = f\"Summarize the following research for the query: {question}\\n\\n\"\n",
    "        for f in findings:\n",
    "            prompt += f\"- {f['title']}\\n  Snippet: {f['snippet']}\\n  Content: {f['text'][:400]}\\n\\n\"\n",
    "\n",
    "        prompt += \"\"\"\n",
    "Provide a clear executive summary:\n",
    "1. Key insights\n",
    "2. Trends\n",
    "3. Recommended next steps\n",
    "\"\"\"\n",
    "\n",
    "        summary = openai_summarize(prompt)\n",
    "        store(\"summary\", summary)\n",
    "        return summary\n",
    "\n",
    "# ================================\n",
    "# WORKFLOW\n",
    "# ================================\n",
    "def run_workflow(query):\n",
    "    init_db()\n",
    "    retriever = SimpleRetriever()\n",
    "    researcher = ResearchAgent(retriever)\n",
    "    summarizer = SummaryAgent()\n",
    "\n",
    "    findings = researcher.research(query)\n",
    "    rag_hits = retriever.retrieve(query, k=3)\n",
    "\n",
    "    # Add RAG results as additional findings\n",
    "    for doc_id, text, score in rag_hits:\n",
    "        findings.append({\"title\": f\"RAG: {doc_id}\", \"snippet\": text[:200], \"text\": text})\n",
    "\n",
    "    summary = summarizer.summarize(findings, query)\n",
    "    return findings, summary\n",
    "\n",
    "# ================================\n",
    "# USER INPUT + EXECUTION\n",
    "# ================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"*****************************************\")\n",
    "    query = input(\"Enter your research query: \")\n",
    "    print(\"*****************************************\")\n",
    "    findings, summary = run_workflow(query)\n",
    "\n",
    "    print(\"\\n=======================\")\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=======================\")\n",
    "    print(summary)\n",
    "\n",
    "    print(\"\\n=======================\")\n",
    "    print(\"RECENT MEMORY\")\n",
    "    print(\"=======================\")\n",
    "    for row in fetch_recent(5):\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52cbbbf-91d7-47dc-a313-56fceffe2a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
